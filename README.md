### Как это работает

Из датасета *BooksDatasetClean.csv* берётся n книг (только их описания). Далее они преобразуются алгоритмом <strong>TFIDF</strong> и сжимаются алгоритмом <strong>PCA</strong>.

В проекте присутствует два алгоритма PCA на выбор, рекомендуется использовать *PCAServiceSVD*, особенно при отсутсвии дискретной видеокарты, так как он оптимизирован для утилизации CPU и выполняет матричные преобразования параллельно.

Также в варианте *PCAServiceSVD* присутствует сохранение векторов преобразования в *.bin* файл и загрузка этих векторов для того, чтобы не повторять тренировку (вычисление векторов преобразования PCA многократно). Данные сохраняются в *"D:/ModelTraining/pca_model_AtoB"* где A - ранг векторов до преобразования, B - после

### Пример в *Program.cs*

В датасет добавляются два различных описания книги "1984" и после по третьему (отличному от первых двух) описанию ищутся наиболее похожие описания. В представленном примере первые два описания книги "1984" - наиболее похожи на третье, что подтверждает, что алгоритм действительно может распозновать похожие тексты.

*<span>P.S В планах - встроить этот алгоритм в систему поиска на сайте проекта по C#, но для этого нужно создать алгоритм быстрого поиска среди векторов. Возможная имплементация - reverse indexing по отдельным измерениям вектора - значение это числа с плавающей запятой, целесообразно будет разделить их на n частей, пример: при n = 10: значения всех векторов хранятся в формате: m таблиц (где m - размерность каждого вектора) в каждой таблице n-1 строк формата range: { (1/n x i), (1/n x (i+1)) }, vectors: все векторы, для которых измерение соответствующее номеру таблицы попадает в range. Далее ищется пересечение векторов в таблицах/строках соответсвующих вектору, по которому ищется соответствие</span>*
